{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99069480-af1c-4456-8161-0293bb77bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "# import xgboost as xgb\n",
    "# import shap\n",
    "import joblib\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# reuse to_numeric_safe from previous notebook (or re-define)\n",
    "def to_numeric_safe(series):\n",
    "    s = series.astype(str).str.strip()\n",
    "    s = s.replace(['nan','NaN','None','NONE','none',''], np.nan)\n",
    "    s = s.str.replace(\".\", \"\", regex=False)\n",
    "    s = s.str.replace(\",\", \".\", regex=False)\n",
    "    s = s.str.replace(\" \", \"\", regex=False)\n",
    "    return pd.to_numeric(s, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "368e5e45-7010-449a-9d9b-cd4e1e50d4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['VehicleType', 'make', 'Model', 'Province', 'Gender', 'VehicleAge', 'IsNewVehicle']\n"
     ]
    }
   ],
   "source": [
    "# cell 2\n",
    "df = pd.read_parquet(\"../data/processed/insurance_data.parquet\")\n",
    "# detect claim column as before\n",
    "claim_cols = [c for c in df.columns if 'claim' in c.lower()]\n",
    "if 'TotalClaims' in df.columns:\n",
    "    claim_col = 'TotalClaims'\n",
    "elif claim_cols:\n",
    "    claim_col = claim_cols[0]\n",
    "else:\n",
    "    raise RuntimeError(\"No claim column found. Add TotalClaims or similar.\")\n",
    "\n",
    "# clean numeric columns\n",
    "df['TotalPremium'] = to_numeric_safe(df['TotalPremium'])\n",
    "df[claim_col] = to_numeric_safe(df[claim_col])\n",
    "df['HasClaim'] = df[claim_col].fillna(0) > 0\n",
    "df['ClaimSeverity'] = df.loc[df['HasClaim'], claim_col]\n",
    "df['Margin'] = df['TotalPremium'] - df[claim_col].fillna(0)\n",
    "\n",
    "# Feature engineering examples\n",
    "df['VehicleAge'] = df['TransactionMonth'].dt.year - df['RegistrationYear']\n",
    "df['IsNewVehicle'] = df['NewVehicle'].fillna('No').map(lambda x: 1 if str(x).lower() in ['yes','y','true','1'] else 0)\n",
    "\n",
    "# choose features (example subset)\n",
    "feature_cols = [\n",
    "    'VehicleType', 'make', 'Model', 'Province', 'Gender',\n",
    "    'VehicleAge', 'IsNewVehicle', 'Kilometers'  # replace Kilometers with an actual column if present\n",
    "]\n",
    "# filter only features present in df\n",
    "feature_cols = [c for c in feature_cols if c in df.columns]\n",
    "print(\"Using features:\", feature_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36ad67ba-21a0-4e73-9182-f924d8ca823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 3\n",
    "# separate numeric & categorical\n",
    "num_feats = [c for c in feature_cols if df[c].dtype.kind in 'biufc']\n",
    "cat_feats = [c for c in feature_cols if c not in num_feats]\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipe, num_feats),\n",
    "    ('cat', cat_pipe, cat_feats)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1cba546-f71f-4e0b-9150-c1635da16686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9972102789721028\n",
      "ROC AUC: 0.6053279962885108\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marshy/FOSS/repos/tenx/w3/dvc-insurance-analysis/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# cell 4\n",
    "X = df[feature_cols].copy()\n",
    "y = df['HasClaim'].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "clf_pipe = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42))\n",
    "])\n",
    "\n",
    "clf_pipe.fit(X_train, y_train)\n",
    "y_pred = clf_pipe.predict(X_test)\n",
    "y_proba = clf_pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7012857-06d1-432d-91c4-e70d9c26f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 5\n",
    "df_claims = df[df['HasClaim']].copy()\n",
    "Xc = df_claims[feature_cols]\n",
    "yc = df_claims['ClaimSeverity'].fillna(0)\n",
    "\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc, test_size=0.2, random_state=42)\n",
    "\n",
    "reg_pipe = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('reg', RandomForestRegressor(n_estimators=200, n_jobs=-1, random_state=42))\n",
    "])\n",
    "\n",
    "reg_pipe.fit(Xc_train, yc_train)\n",
    "yc_pred = reg_pipe.predict(Xc_test)\n",
    "\n",
    "rmse = mean_squared_error(yc_test, yc_pred, squared=False)\n",
    "r2 = r2_score(yc_test, yc_pred)\n",
    "print(\"Severity RMSE:\", rmse)\n",
    "print(\"Severity R2:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0acbd2ae-f4da-4f7f-8069-b4729d63272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 6\n",
    "X_p = df[feature_cols]\n",
    "y_p = df['TotalPremium']\n",
    "\n",
    "Xp_train, Xp_test, yp_train, yp_test = train_test_split(X_p, y_p, test_size=0.2, random_state=42)\n",
    "\n",
    "premium_pipe = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('reg', xgb.XGBRegressor(objective='reg:squarederror', n_estimators=200, n_jobs=-1, random_state=42))\n",
    "])\n",
    "\n",
    "premium_pipe.fit(Xp_train, yp_train)\n",
    "yp_pred = premium_pipe.predict(Xp_test)\n",
    "\n",
    "print(\"Premium RMSE:\", mean_squared_error(yp_test, yp_pred, squared=False))\n",
    "print(\"Premium R2:\", r2_score(yp_test, yp_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2f791c4-8d61-42bc-bd54-089400f605d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Province - frequency: REJECT H0 (p=5.926e-19) — statistically significant difference.\n",
      "Province - severity: FAIL TO REJECT H0 (p=0.05348) — no evidence of difference.\n",
      "TopZIPs - frequency: REJECT H0 (p=2.603e-14) — statistically significant difference.\n",
      "Gender - frequency: REJECT H0 (p=0.02657) — statistically significant difference.\n"
     ]
    }
   ],
   "source": [
    "# cell 7\n",
    "# You can wrap the training blocks in functions and run different models (LinearRegression, RF, XGBoost)\n",
    "# Save best models\n",
    "joblib.dump(clf_pipe, \"models/claim_prob_rf.pkl\")\n",
    "joblib.dump(reg_pipe, \"models/claim_severity_rf.pkl\")\n",
    "joblib.dump(premium_pipe, \"models/premium_xgb.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97629e4-9323-45bc-900b-2533f95bd4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 8\n",
    "# Example for claim severity model (random forest). We need the transformed feature names.\n",
    "prep = reg_pipe.named_steps['prep']\n",
    "X_sample = Xc_train.sample(200, random_state=1)\n",
    "X_trans = prep.transform(X_sample)\n",
    "# get feature names from column transformer\n",
    "num_names = num_feats\n",
    "cat_names = list(prep.named_transformers_['cat'].named_steps['ohe'].get_feature_names_out(cat_feats)) if cat_feats else []\n",
    "feature_names = num_names + cat_names\n",
    "\n",
    "explainer = shap.TreeExplainer(reg_pipe.named_steps['reg'])\n",
    "shap_values = explainer.shap_values(X_trans)\n",
    "shap.summary_plot(shap_values, X_trans, feature_names=feature_names, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e86ccf8-d4a9-497f-be11-2bc90b947946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=['No Claim', 'Has Claim'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix — Claim Occurrence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f53b46c-2497-4dde-bb09-cd8e94dbe4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_proba)\n",
    "plt.title(\"ROC Curve — Claim Occurrence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102ed79-f955-4381-bdfa-a9d6c28c2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(y_test, y_proba)\n",
    "plt.title(\"Precision–Recall Curve — Claim Occurrence\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51741668-839e-4ecf-905c-bc07d67af655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "residuals = yc_test - yc_pred\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(x=yc_pred, y=residuals, alpha=0.3)\n",
    "plt.axhline(0, color='red')\n",
    "plt.xlabel(\"Predicted Severity\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot — Claim Severity\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cff8a6b-b96b-44c1-9dfe-229fcf8d0f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=yc_test, y=yc_pred, alpha=0.3)\n",
    "plt.plot([yc_test.min(), yc_test.max()], [yc_test.min(), yc_test.max()], color='red')\n",
    "plt.xlabel(\"Actual Severity\")\n",
    "plt.ylabel(\"Predicted Severity\")\n",
    "plt.title(\"Actual vs Predicted — Claim Severity\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7001d-8124-4c25-b987-0dda7bdca3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "residuals_p = yp_test - yp_pred\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(x=yp_pred, y=residuals_p, alpha=0.3)\n",
    "plt.axhline(0, color='red')\n",
    "plt.xlabel(\"Predicted Premium\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot — Premium Prediction\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fdbc91-116f-4680-8b2c-4b343a4e0d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=yp_test, y=yp_pred, alpha=0.3)\n",
    "plt.plot([yp_test.min(), yp_test.max()], [yp_test.min(), yp_test.max()], color='red')\n",
    "plt.xlabel(\"Actual Premium\")\n",
    "plt.ylabel(\"Predicted Premium\")\n",
    "plt.title(\"Actual vs Predicted — Premium Regression\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6935b505-2d55-4b74-8fae-db78095e12e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf_pipe.named_steps['clf']\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# This is the ONLY correct way\n",
    "prep = clf_pipe.named_steps[\"prep\"]\n",
    "feature_names = prep.get_feature_names_out()\n",
    "\n",
    "print(\"Model feature count:\", len(importances))\n",
    "print(\"Name count:\", len(feature_names))\n",
    "\n",
    "# Build importance series\n",
    "fi = pd.Series(importances, index=feature_names).sort_values(ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=fi.values, y=fi.index)\n",
    "plt.title(\"Top 20 Feature Importances — Claim Classification\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv - WA3",
   "language": "python",
   "name": "financial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
